{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# VGG Face\n",
    "\n",
    "VGG is a famous model in machine learning known for very good image recognician results. Here we are going to use this to recognize faces. One of the last tricks that Keras has to offer is a large community of developers adding models to the enviornment. VGG face is not something new. It was developed as [Deep Face Recognition](http://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf) at Oxford and has since been ported over. Below we mock out the model and use pretrained weights to get things up and running as quickly as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import warnings\n",
    "\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Input, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_v2.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_v2.h5'\n",
    "\n",
    "\n",
    "\n",
    "def VGGFace(include_top=True, weights='vggface',\n",
    "            input_tensor=None, input_shape=None,\n",
    "            pooling=None,\n",
    "            classes=2622):\n",
    "    \"\"\"Instantiates the VGGFace architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on VGGFace dataset. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 244)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "\n",
    "    if weights not in {'vggface', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `vggface` '\n",
    "                         '(pre-training on VGGFace Dataset).')\n",
    "\n",
    "    if weights == 'vggface' and include_top and classes != 2622:\n",
    "        raise ValueError('If using `weights` as vggface original with `include_top`'\n",
    "                         ' as true, `classes` should be 2622')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    # Block 1\n",
    "    x = Convolution2D(64, (3, 3), activation='relu', padding='same', name='conv1_1')(img_input)\n",
    "    x = Convolution2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Convolution2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(x)\n",
    "    x = Convolution2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Convolution2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(x)\n",
    "    x = Convolution2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(x)\n",
    "    x = Convolution2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Convolution2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(x)\n",
    "    x = Convolution2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(x)\n",
    "    x = Convolution2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Convolution2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(x)\n",
    "    x = Convolution2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(x)\n",
    "    x = Convolution2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc6')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc7')(x)\n",
    "        x = Dense(2622, activation='softmax', name='fc8')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "            # Ensure that the model takes into account\n",
    "            # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "        # Create model.\n",
    "    model = Model(inputs, x, name='VGGFace')  # load weights\n",
    "    if weights == 'vggface':\n",
    "        if include_top:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_v2.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('rcmalli_vggface_tf_notop_v2.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='pool5')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc6')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_v2.h5\n"
     ]
    }
   ],
   "source": [
    "model = VGGFace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "img = image.load_img('some-celeb.jpg', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "# TF order aka 'channel-last'\n",
    "x = x[:, :, :, ::-1]\n",
    "# TH order aka 'channel-first'\n",
    "# x = x[:, ::-1, :, :]\n",
    "# Zero-center by mean pixel\n",
    "x[:, 0, :, :] -= 93.5940\n",
    "x[:, 1, :, :] -= 104.7624\n",
    "x[:, 2, :, :] -= 129.1863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "print('Predicted:', np.argmax(preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A.J._Buckley.txt'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('famous.txt.npy')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Can it recognize us??\n",
    "\n",
    "The model above is about as complex as one that you will see and use. With multiple layer types and deep connections it can be confusing, but the best way to learn to swim is to go into the deep end.\n",
    "\n",
    "Below I have a couple of tasks that we should now be able to do:\n",
    "\n",
    "1. See which celeb you look closest to by feeding in your own image\n",
    "2. Check out how you look after the first convolutional layer. The second?\n",
    "3. Train a new recognizer to recognize the pictures that the class has given in. Can it recognize yours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Do you remember how we did this last time:\n",
    "\n",
    "`K.function([model.input], [layer.output])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The code below should be a good starting point. Can you answer why we just removed the top few layers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.engine import  Model\n",
    "from keras.layers import Flatten, Dense, Input\n",
    "\n",
    "\n",
    "#custom parameters\n",
    "nb_class = ?\n",
    "hidden_dim = 512\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "# for theano uncomment\n",
    "# image_input = Input(shape=(3,224, 224))\n",
    "vgg_model = VGGFace(input_tensor=image_input, include_top=False)\n",
    "last_layer = vgg_model.get_layer('pool5').output\n",
    "x = Flatten(name='flatten')(last_layer)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
    "x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
    "out = Dense(nb_class, activation='softmax', name='fc8')(x)\n",
    "custom_vgg_model = Model(image_input, out)\n",
    "\n",
    "# Train your model as usual.\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
